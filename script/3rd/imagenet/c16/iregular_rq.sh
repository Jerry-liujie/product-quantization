# Parameters: dataset = imagenet, topK = 1000, Ks = 256, metric = euclid
# load the base data data/imagenet/imagenet_base.fvecs,
# load the queries data/imagenet/imagenet_query.fvecs,
# load the ground truth data/imagenet/1000_imagenet_euclid_groundtruth.ivecs
#    Training the subspace: 0 / 2, 0 -> 75
#    Training the subspace: 1 / 2, 75 -> 150
# compress items with imi
# train hierarchy rqs on residuals
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 0,  residual average norm : 0.17004860937595367 max norm: 0.736886203289032 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 1,  residual average norm : 0.15637101233005524 max norm: 0.6495445966720581 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 2,  residual average norm : 0.14629524946212769 max norm: 0.6250254511833191 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 3,  residual average norm : 0.13819414377212524 max norm: 0.5176790952682495 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 4,  residual average norm : 0.13120189309120178 max norm: 0.4928503930568695 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 5,  residual average norm : 0.1250835806131363 max norm: 0.4443725645542145 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 6,  residual average norm : 0.119605652987957 max norm: 0.4226495325565338 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 7,  residual average norm : 0.11469894647598267 max norm: 0.39652666449546814 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 8,  residual average norm : 0.11011072993278503 max norm: 0.3601760268211365 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 9,  residual average norm : 0.10587983578443527 max norm: 0.35209307074546814 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 10,  residual average norm : 0.10198618471622467 max norm: 0.34597957134246826 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 11,  residual average norm : 0.09834984689950943 max norm: 0.3011719584465027 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 12,  residual average norm : 0.09498744457960129 max norm: 0.279063880443573 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 13,  residual average norm : 0.09178536385297775 max norm: 0.2727428376674652 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 14,  residual average norm : 0.08872193098068237 max norm: 0.26124435663223267 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 15,  residual average norm : 0.0858815461397171 max norm: 0.25233954191207886 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 16,  residual average norm : 0.08310963213443756 max norm: 0.24406349658966064 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 17,  residual average norm : 0.0805220976471901 max norm: 0.2295871078968048 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 18,  residual average norm : 0.07806972414255142 max norm: 0.22218802571296692 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 0,  residual average norm : 0.170022651553154 max norm: 0.7113112807273865 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 1,  residual average norm : 0.15627340972423553 max norm: 0.5979031920433044 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 2,  residual average norm : 0.14620958268642426 max norm: 0.5492295026779175 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 3,  residual average norm : 0.13803422451019287 max norm: 0.49917107820510864 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 4,  residual average norm : 0.13112623989582062 max norm: 0.47496867179870605 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 5,  residual average norm : 0.12513339519500732 max norm: 0.43360209465026855 min norm: 0.0
#    Training the subspace: 0 / 1, 0 -> 150
# layer: 6,  residual average norm : 0.11973890662193298 max norm: 0.41877683997154236 min norm: 0.0
# compress items with rq
# compress norm
#    Training the subspace: 0 / 1, 0 -> 1
#    Training the subspace: 0 / 1, 0 -> 1
# imi full sort and generate candidate
# probe
#
# probe 16 items
# hierarchy_index [ 0 10 16]
Probe, top-K, 00001.,  00002.,  00004.,  00008.,  00016.,  00032.,  00064.,  00128.,  00256.,  00512.,  01024.,  02048.,  04096.,  08192.,  16384.,  32768.,  65536.,  131072.,
   16,    1,  0.2950,  0.2950,  0.2950,  0.2950,  0.2950,  0.2950,  0.2950,  0.2950,  0.2950,  0.2950,  0.2950,  0.2950,  0.2950,  0.2950,  0.2950,  0.2950,  0.2950,  0.2950,
   16,   10,  0.0345,  0.0395,  0.0405,  0.0405,  0.0405,  0.0405,  0.0405,  0.0405,  0.0405,  0.0405,  0.0405,  0.0405,  0.0405,  0.0405,  0.0405,  0.0405,  0.0405,  0.0405,
   16,   20,  0.0177,  0.0212,  0.0230,  0.0230,  0.0230,  0.0230,  0.0230,  0.0230,  0.0230,  0.0230,  0.0230,  0.0230,  0.0230,  0.0230,  0.0230,  0.0230,  0.0230,  0.0230,
   16,   50,  0.0081,  0.0102,  0.0114,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,
   16,  100,  0.0047,  0.0063,  0.0072,  0.0075,  0.0076,  0.0076,  0.0076,  0.0076,  0.0076,  0.0076,  0.0076,  0.0076,  0.0076,  0.0076,  0.0076,  0.0076,  0.0076,  0.0076,
   16, 1000,  0.0007,  0.0012,  0.0017,  0.0021,  0.0022,  0.0022,  0.0022,  0.0022,  0.0022,  0.0022,  0.0022,  0.0022,  0.0022,  0.0022,  0.0022,  0.0022,  0.0022,  0.0022,
#
# probe 256 items
# hierarchy_index [  0 170 256]
Probe, top-K, 00001.,  00002.,  00004.,  00008.,  00016.,  00032.,  00064.,  00128.,  00256.,  00512.,  01024.,  02048.,  04096.,  08192.,  16384.,  32768.,  65536.,  131072.,
  256,    1,  0.8600,  0.8600,  0.8600,  0.8600,  0.8600,  0.8600,  0.8600,  0.8600,  0.8600,  0.8600,  0.8600,  0.8600,  0.8600,  0.8600,  0.8600,  0.8600,  0.8600,  0.8600,
  256,   10,  0.0900,  0.1260,  0.1535,  0.1745,  0.1855,  0.1885,  0.1895,  0.1895,  0.1895,  0.1895,  0.1895,  0.1895,  0.1895,  0.1895,  0.1895,  0.1895,  0.1895,  0.1895,
  256,   20,  0.0452,  0.0678,  0.0932,  0.1165,  0.1295,  0.1347,  0.1367,  0.1367,  0.1370,  0.1370,  0.1370,  0.1370,  0.1370,  0.1370,  0.1370,  0.1370,  0.1370,  0.1370,
  256,   50,  0.0185,  0.0312,  0.0472,  0.0650,  0.0806,  0.0890,  0.0927,  0.0932,  0.0933,  0.0933,  0.0933,  0.0933,  0.0933,  0.0933,  0.0933,  0.0933,  0.0933,  0.0933,
  256,  100,  0.0094,  0.0165,  0.0273,  0.0417,  0.0566,  0.0664,  0.0707,  0.0716,  0.0717,  0.0717,  0.0717,  0.0717,  0.0717,  0.0717,  0.0717,  0.0717,  0.0717,  0.0717,
  256, 1000,  0.0010,  0.0019,  0.0036,  0.0067,  0.0120,  0.0193,  0.0261,  0.0291,  0.0294,  0.0294,  0.0294,  0.0294,  0.0294,  0.0294,  0.0294,  0.0294,  0.0294,  0.0294,

# probe 1024 items
# hierarchy_index [   0  682 1024]
Probe, top-K, 00001.,  00002.,  00004.,  00008.,  00016.,  00032.,  00064.,  00128.,  00256.,  00512.,  01024.,  02048.,  04096.,  08192.,  16384.,  32768.,  65536.,  131072.,
 1024,    1,  0.9650,  0.9650,  0.9700,  0.9700,  0.9700,  0.9700,  0.9700,  0.9700,  0.9700,  0.9700,  0.9700,  0.9700,  0.9700,  0.9700,  0.9700,  0.9700,  0.9700,  0.9700,
 1024,   10,  0.0975,  0.1500,  0.2210,  0.2800,  0.3160,  0.3395,  0.3495,  0.3515,  0.3515,  0.3520,  0.3520,  0.3520,  0.3520,  0.3520,  0.3520,  0.3520,  0.3520,  0.3520,
 1024,   20,  0.0488,  0.0800,  0.1268,  0.1808,  0.2330,  0.2667,  0.2812,  0.2858,  0.2865,  0.2870,  0.2870,  0.2870,  0.2870,  0.2870,  0.2870,  0.2870,  0.2870,  0.2870,
 1024,   50,  0.0198,  0.0343,  0.0602,  0.0984,  0.1454,  0.1918,  0.2169,  0.2258,  0.2283,  0.2285,  0.2285,  0.2285,  0.2285,  0.2285,  0.2285,  0.2285,  0.2285,  0.2285,
 1024,  100,  0.0099,  0.0179,  0.0325,  0.0564,  0.0924,  0.1372,  0.1729,  0.1896,  0.1938,  0.1941,  0.1942,  0.1942,  0.1942,  0.1942,  0.1942,  0.1942,  0.1942,  0.1942,
 1024, 1000,  0.0010,  0.0019,  0.0038,  0.0074,  0.0141,  0.0264,  0.0461,  0.0715,  0.0906,  0.0963,  0.0967,  0.0967,  0.0967,  0.0967,  0.0967,  0.0967,  0.0967,  0.0967,

# probe 4096 items
# hierarchy_index [   0 2730 4096]
Probe, top-K, 00001.,  00002.,  00004.,  00008.,  00016.,  00032.,  00064.,  00128.,  00256.,  00512.,  01024.,  02048.,  04096.,  08192.,  16384.,  32768.,  65536.,  131072.,
 4096,    1,  0.9850,  0.9850,  0.9850,  0.9850,  0.9850,  0.9850,  0.9850,  0.9850,  0.9850,  0.9850,  0.9850,  0.9850,  0.9850,  0.9850,  0.9850,  0.9850,  0.9850,  0.9850,
 4096,   10,  0.0985,  0.1645,  0.2645,  0.3860,  0.4920,  0.5585,  0.5915,  0.6050,  0.6085,  0.6085,  0.6090,  0.6090,  0.6090,  0.6090,  0.6090,  0.6090,  0.6090,  0.6090,
 4096,   20,  0.0493,  0.0865,  0.1497,  0.2408,  0.3570,  0.4532,  0.5060,  0.5320,  0.5400,  0.5413,  0.5420,  0.5423,  0.5423,  0.5423,  0.5423,  0.5423,  0.5423,  0.5423,
 4096,   50,  0.0199,  0.0369,  0.0673,  0.1177,  0.2037,  0.3049,  0.3986,  0.4522,  0.4701,  0.4742,  0.4751,  0.4752,  0.4752,  0.4752,  0.4752,  0.4752,  0.4752,  0.4752,
 4096,  100,  0.0100,  0.0188,  0.0357,  0.0651,  0.1183,  0.1980,  0.3008,  0.3822,  0.4186,  0.4276,  0.4290,  0.4291,  0.4291,  0.4291,  0.4291,  0.4291,  0.4291,  0.4291,
 4096, 1000,  0.0010,  0.0020,  0.0039,  0.0077,  0.0151,  0.0291,  0.0554,  0.1014,  0.1689,  0.2362,  0.2666,  0.2702,  0.2704,  0.2704,  0.2704,  0.2704,  0.2704,  0.2704,

# probe 16384 items
# hierarchy_index [    0 10922 16384]
Probe, top-K, 00001.,  00002.,  00004.,  00008.,  00016.,  00032.,  00064.,  00128.,  00256.,  00512.,  01024.,  02048.,  04096.,  08192.,  16384.,  32768.,  65536.,  131072.,
16384,    1,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,
16384,   10,  0.1000,  0.1705,  0.2875,  0.4430,  0.6125,  0.7330,  0.8095,  0.8420,  0.8535,  0.8585,  0.8590,  0.8595,  0.8595,  0.8595,  0.8595,  0.8595,  0.8595,  0.8595,
16384,   20,  0.0500,  0.0895,  0.1595,  0.2745,  0.4405,  0.6065,  0.7242,  0.7863,  0.8117,  0.8200,  0.8213,  0.8225,  0.8225,  0.8225,  0.8225,  0.8225,  0.8225,  0.8225,
16384,   50,  0.0200,  0.0376,  0.0700,  0.1318,  0.2347,  0.3830,  0.5563,  0.6884,  0.7508,  0.7745,  0.7789,  0.7803,  0.7803,  0.7803,  0.7803,  0.7803,  0.7803,  0.7803,
16384,  100,  0.0100,  0.0192,  0.0366,  0.0699,  0.1321,  0.2364,  0.3911,  0.5618,  0.6818,  0.7303,  0.7422,  0.7454,  0.7457,  0.7457,  0.7457,  0.7457,  0.7457,  0.7457,
16384, 1000,  0.0010,  0.0020,  0.0039,  0.0078,  0.0153,  0.0302,  0.0588,  0.1130,  0.2088,  0.3557,  0.5096,  0.5791,  0.5887,  0.5894,  0.5894,  0.5894,  0.5894,  0.5894,

# probe 65536 items
# hierarchy_index [    0 43690 65536]
Probe, top-K, 00001.,  00002.,  00004.,  00008.,  00016.,  00032.,  00064.,  00128.,  00256.,  00512.,  01024.,  02048.,  04096.,  08192.,  16384.,  32768.,  65536.,  131072.,
65536,    1,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,
65536,   10,  0.1000,  0.1765,  0.3055,  0.4890,  0.6765,  0.8275,  0.9205,  0.9560,  0.9700,  0.9755,  0.9765,  0.9780,  0.9780,  0.9780,  0.9780,  0.9780,  0.9780,  0.9780,
65536,   20,  0.0500,  0.0940,  0.1720,  0.3003,  0.4898,  0.6887,  0.8425,  0.9207,  0.9560,  0.9680,  0.9698,  0.9720,  0.9720,  0.9720,  0.9720,  0.9720,  0.9720,  0.9720,
65536,   50,  0.0200,  0.0390,  0.0745,  0.1423,  0.2586,  0.4297,  0.6460,  0.8251,  0.9189,  0.9550,  0.9651,  0.9679,  0.9681,  0.9681,  0.9681,  0.9681,  0.9681,  0.9681,
65536,  100,  0.0100,  0.0196,  0.0381,  0.0740,  0.1428,  0.2596,  0.4435,  0.6647,  0.8422,  0.9258,  0.9496,  0.9567,  0.9579,  0.9579,  0.9579,  0.9579,  0.9579,  0.9579,
65536, 1000,  0.0010,  0.0020,  0.0040,  0.0079,  0.0157,  0.0312,  0.0615,  0.1200,  0.2281,  0.4114,  0.6532,  0.8331,  0.8893,  0.8977,  0.8983,  0.8983,  0.8983,  0.8983,