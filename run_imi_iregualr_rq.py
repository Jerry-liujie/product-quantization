from sorter import *
from transformer import *
from vecs_io import loader
from pq_residual import ResidualPQ

from run_imi_pq import chunk_compress
from run_imi_pq import parse_args
from run_imi_pq import print_recalls


def run_ex(dataset, topk, Ks, metric):

    ### load data
    X, T, Q, G = loader(dataset, topk, metric, folder='data/')
    N, D = np.shape(X)
    if T is None:
        T = X[:100000]
    Q = Q[:200, :]
    G = G[:200, :]

    # imi for candidate generation
    imi = PQ(M=2, Ks=Ks)
    imi.fit(T.astype(dtype=np.float32), iter=20)

    print('# compress items with imi')
    imi_compressed = chunk_compress(imi, X)
    residual = X - imi_compressed

    # number of codebook used to reconstruct items
    # for top 20% candidates, which is generated by imi, we use 32-1 codebook
    # for top 20% candidates, which is generated by imi, we use 32-1 codebook
    hierarchy_codebook = np.array([20, 8]) - 1
    hierarchy_percent =  [0, 8/12.0, 4/12.0]

    # construct RQs
    def gen_rq(num_codebook):
        return ResidualPQ(pqs=[PQ(M=1, Ks=Ks) for _ in range(num_codebook)])
    rqs = [gen_rq(codebook) for codebook in hierarchy_codebook]
    print("# train hierarchy rqs on residuals")
    [rq.fit(residual[:100000], iter=20) for rq in rqs]
    print("# compress items with rq")
    hierarchy_compressed = [chunk_compress(rq, residual) + imi_compressed for rq in rqs]
    del residual

    # if compress norm
    print("# compress norm")
    x_full_compress = hierarchy_compressed[0]
    norm_sqr = np.sum(x_full_compress * x_full_compress, axis=1, keepdims=True)
    norm_quantizer = PQ(M=1, Ks=256).fit(norm_sqr, iter=20)
    compressed_norm_sqr = chunk_compress(norm_quantizer, norm_sqr).reshape((-1))
    del norm_sqr

    print("# imi full sort")
    sorted_candidate = np.empty((len(Q), len(X)), dtype=np.int32)
    for i in tqdm.tqdm(nb.prange(len(Q))):
        sorted_candidate[i, :] = np.argsort(np.linalg.norm(Q[i] - imi_compressed, axis=1))

    print("# probe ")
    probed_items = [2 ** i for i in [4, 8, 10, 12, 14, 16]]
    for n_item in probed_items:
        probe_size = min(131072, n_item)
        I = np.empty((Q.shape[0], probe_size - 1), dtype=np.int32)
        compressed = np.empty(shape=(probe_size, D), dtype=np.float32)

        hierarchy_index = np.array(np.cumsum(hierarchy_percent) * probe_size).astype(np.int)
        hierarchy_index[-1] = probe_size

        print()
        print('# probe {} items'.format(probe_size))
        print("# hierarchy_index {}".format(hierarchy_index))

        for q in nb.prange(Q.shape[0]):
            for v in nb.prange(0, len(hierarchy_index) - 1):
                candidate_id = sorted_candidate[q, hierarchy_index[v]:hierarchy_index[v+1]]
                compressed[hierarchy_index[v]:hierarchy_index[v+1], :] = hierarchy_compressed[v][candidate_id, :]

            candidate_norm_sqr = compressed_norm_sqr[sorted_candidate[q, :probe_size]]
            sort_by_pq = euclidean_norm_arg_sort(Q[q], compressed, candidate_norm_sqr)
            # sort_by_pq = euclidean_arg_sort(Q[q], compressed)
            I[q, :] = sorted_candidate[q, sort_by_pq]

        print_recalls(probe_size, Q, G, I)
        del I
        del compressed


if __name__ == '__main__':
    dataset = 'imagenet'
    topk = 1000
    Ks = 256
    metric = 'euclid'

    # override default parameters with command line parameters
    import sys
    if len(sys.argv) > 3:
        dataset, topk, codebook, Ks, metric = parse_args()
    else:
        import warnings
        warnings.warn("Using  Default Parameters ")
    print("# Parameters: dataset = {}, topK = {}, Ks = {}, metric = {}"
          .format(dataset, topk, Ks, metric))

    run_ex(dataset, topk, Ks, metric)

